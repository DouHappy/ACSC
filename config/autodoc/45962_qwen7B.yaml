# 中文错别字纠正项目配置文件
# CUDA_VISIBLE_DEVICES=0 python main.py --config config/autodoc/45962_qwen7B.yaml --mode full
# CUDA_VISIBLE_DEVICES=0 python main.py --config config/autodoc/45962_qwen7B.yaml --mode evaluation
# 数据集配置
dataset:
  path: "/home/yangchunhao/csc/datasets/autodoc_csc/autodoc_csc.json"  # 本地数据文件路径
  format: "autodoc"  # 数据格式：{"source": str, "reason": str/None}

# Prompt配置
prompts:
  file_path: "prompts/prompts.json"
  name: "detect"
  
# 模型配置
model:
  model_name: "/data/images/llms/Qwen/Qwen2.5-VL-7B-Instruct"  # 模型名称或路径
  backend: "vllm"  # 推理后端：vllm 或 huggingface
  max_tokens: 512  # 最大生成token数
  temperature: 0  # 温度参数
  top_p: 0.9  # top-p采样参数
  gpu_memory_utilization: 0.9  # GPU内存使用率
  tensor_parallel_size: 1  # 张量并行大小
  max_model_len: 5120
  
# 评估配置
evaluation:
  output_dir: "results/45962_qwen7B"
  ignore_punct: true
  task_type: "review"
  
# 训练/推理配置
pipeline:
  type: "icl"  # 推理类型：icl (in-context learning)
  max_samples: null  # 最大样本数，null表示使用全部数据
  output_dir: "results/45962_qwen7B"
  batch:
    size: 1024
  
# 日志配置
logging:
  level: "INFO"
  file_path: "logs/csc.log"
  console: true
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
